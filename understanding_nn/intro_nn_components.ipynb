{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "178dedd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBreakdown of a simple neural network\\n\\nX --> input\\nWx --> Weights\\nbx --> bias\\nA --> Activation Function\\nY --> Output\\n\\n\\nz = W1.X + b1\\noutput(z') = fn(z)  # fn = activation fn\\nY = fn(W2.z' + b2)\\n\\n# Loss Function\\n# Backpropagation\\n# optimizers\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Breakdown of a simple neural network\n",
    "\n",
    "X --> input\n",
    "Wx --> Weights\n",
    "bx --> bias\n",
    "A --> Activation Function\n",
    "Y --> Output\n",
    "\n",
    "\n",
    "z = W1.X + b1\n",
    "output(z') = fn(z)  # fn = activation fn\n",
    "Y = fn(W2.z' + b2)\n",
    "\n",
    "# Loss Function\n",
    "# Backpropagation\n",
    "# optimizers\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e584aa",
   "metadata": {},
   "source": [
    "##### Components  of NN by pytorch\n",
    "###### --- Base class for defining custom model : torch.nn.model\n",
    "###### --- Fully Connected (dense) layers : torch.nn.Linear\n",
    "###### --- Activation function : torch.nn.ReLU\n",
    "###### --- Optimizers : torch.optim\n",
    "###### --- Loss Function : torch.nn.CrossEntropyLoss\n",
    "###### --- Loads data in batch : torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fdfbb",
   "metadata": {},
   "source": [
    "##### Different ways to create neural network\n",
    "###### 1. Function :Flexible, hard to interpret\n",
    "###### 2. Sequential : nn.sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3791d92",
   "metadata": {},
   "source": [
    "### Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97482262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "612aa8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functional API\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(SimpleNN,self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=input_size,out_features=hidden_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size,out_features=output_size)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        x  = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b05352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential \n",
    "\n",
    "class SimpleNNSequential(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(SimpleNN,self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(nn.Linear(input_size,hidden_size),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_size,output_size),\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371395b0",
   "metadata": {},
   "source": [
    "###### Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f9f6629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_func = SimpleNN(input_size=4,hidden_size=8,output_size=3)\n",
    "print(model_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95f6a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(10,4) # 10 samples, 4 features \n",
    "\n",
    "y = torch.randint(0,3,(10,))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_func.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7801f86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.5813e-01, 6.3922e-01, 7.7537e-01, 1.1669e-01],\n",
      "        [7.2509e-01, 2.4804e-01, 4.9579e-01, 9.9006e-01],\n",
      "        [7.3004e-02, 3.3832e-01, 2.2514e-01, 9.2945e-03],\n",
      "        [2.0294e-01, 3.1091e-01, 3.5548e-01, 1.1910e-01],\n",
      "        [5.2973e-01, 2.2282e-01, 1.9942e-01, 2.2325e-01],\n",
      "        [2.0735e-01, 1.2526e-01, 7.2377e-01, 3.4844e-02],\n",
      "        [3.6621e-01, 4.8224e-01, 6.7055e-05, 4.0698e-01],\n",
      "        [7.1286e-01, 6.7241e-01, 2.5124e-01, 4.8429e-01],\n",
      "        [1.8824e-01, 4.2858e-01, 6.6050e-02, 8.2138e-01],\n",
      "        [2.4772e-01, 8.3799e-01, 4.5208e-01, 1.2693e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ceb5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 1, 1, 0, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a367e",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58485f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]/50, Loss : 1.0710\n",
      "Epoch [20]/50, Loss : 1.0368\n",
      "Epoch [30]/50, Loss : 0.9868\n",
      "Epoch [40]/50, Loss : 0.9205\n",
      "Epoch [50]/50, Loss : 0.8412\n",
      "Epoch [60]/50, Loss : 0.7559\n",
      "Epoch [70]/50, Loss : 0.6710\n",
      "Epoch [80]/50, Loss : 0.5895\n",
      "Epoch [90]/50, Loss : 0.5138\n",
      "Epoch [100]/50, Loss : 0.4478\n",
      "Epoch [110]/50, Loss : 0.3907\n",
      "Epoch [120]/50, Loss : 0.3409\n"
     ]
    }
   ],
   "source": [
    "epochs = 120\n",
    "for e in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_func(X)\n",
    "    loss  = criterion(outputs,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (e+1) % 10 == 0:\n",
    "        print(f\"Epoch [{e+1}]/50, Loss : {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
