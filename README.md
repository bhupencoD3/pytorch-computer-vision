
# PyTorch for Computer Vision ‚Äì Learning Repository

A hands-on learning repository where I document my journey of mastering PyTorch for computer vision.
Each notebook isn‚Äôt just code ‚Äî it‚Äôs me exploring a concept, testing it out, and noting down the takeaways.

---

## üìÇ Repository Structure

### 1. **Intro to Tensors**

* *Notebook:* `intro_to_tensors/`
* Learned how to create PyTorch tensors and explored their basic properties like shape, dtype, and device.
* Practiced creating scalars, vectors, matrices, and higher-dimensional tensors.

---

### 2. **Tensor Indexing**

* *Notebook:* `tensor_indexing/`
* Worked on slicing and indexing operations to access elements of tensors.
* Explored fancy indexing and how it helps in selecting rows/columns in datasets.

---

### 3. **Noise Images**

* *Notebook:* `Noise_images/random_number_noise_image.ipynb`
* Generated random noise images using PyTorch tensors.
* Learned how randomness is used in initialization for neural networks and data augmentation.

---

### 4. **Tensor of Zeros & Ones**

* *Notebook:* `tensor_zeros_ones/tensor_of_zeros_ones.ipynb`
* Created tensors filled with zeros and ones ‚Äî the building blocks of most neural networks.
* Understood why initialization matters in deep learning.

---

### 5. **Tensor DataTypes**

* *Notebook:* `tensor_datatypes/datatypes.ipynb`
* Explored different tensor data types like `float32`, `int64`, etc.
* Noted how dtype affects precision, memory usage, and model performance.

---

### 6. **Tensor Manipulation**

* *Notebook:* `tensor_manipulation/tensor_manipulation.ipynb`
* Practiced reshaping tensors using `view`, `reshape`, `squeeze`, `unsqueeze`, and `transpose`.
* Learned why shape manipulation is critical in building neural networks.

---

### 7. **View & Reshape**

* *Notebook:* `view_reshape/view_reshape_operation.ipynb`
* Focused specifically on the difference between `view()` and `reshape()`.
* Understood memory sharing vs copying, and when to prefer one over the other.

---

### 8. **Tensor Stack**

* *Notebook:* `tensor_stack/stack_operation.ipynb`
* Learned how to combine multiple tensors using `torch.stack` and compared it with `cat()`.
* Practiced stacking in different dimensions to prepare tensors for batch operations.

---

### 9. **Matrix Aggregation**

* *Notebook:* `matrix_aggregation/Matrix_Aggregation.ipynb`
* Explored reduction operations like `sum`, `mean`, `min`, and `max` on tensors.
* Learned how aggregation is used for loss functions and evaluation metrics.

---
### 10. Intro to Neural Network Components

* Notebook: understanding_nn/intro_nn_components.ipynb

* Learned how to define neural networks in PyTorch using both the functional API and nn.Sequential.

* Explored key building blocks like layers, activations, and forward passes, understanding how they connect into a full model.

* Practiced creating simple networks in two styles to compare flexibility vs. readability.

## üõ†Ô∏è Tech Stack

* **Python 3**
* **PyTorch**
* **NumPy**
* **Matplotlib**

---

## üìå Notes

* This repo is strictly for **learning purposes** ‚Äî every notebook documents my understanding of PyTorch step by step.
* Upcoming work: moving from tensor basics to actual **deep learning workflows** (image classification, CNNs, etc.).

---

## üìú License

This project is licensed under the [MIT License](LICENSE).

---

## üë§ Author

**Bhupen** ‚Äì *Learning & building one frame at a time*
[LinkedIn](https://www.linkedin.com/in/bhupenparmar/) | [GitHub](https://github.com/bhupencoD3)
